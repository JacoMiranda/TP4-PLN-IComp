# ğŸ“Š AnÃ¡lise Quantitativa do Trade-off entre EspecializaÃ§Ã£o e GeneralizaÃ§Ã£o em LLMs via Fine-Tuning - By JacÃ³ Miranda

Este projeto implementa uma avaliaÃ§Ã£o empÃ­rica e sistemÃ¡tica do processo de fine-tuning em Modelos de Linguagem de Grande Porte (LLMs), focando na quantificaÃ§Ã£o do ganho de desempenho na tarefa-alvo (Text-to-SQL) e na mediÃ§Ã£o da degradaÃ§Ã£o de performance em tarefas de conhecimento geral (MMLU).

## ğŸ“‹ Objetivo

Avaliar quantitativamente o trade-off entre especializaÃ§Ã£o e generalizaÃ§Ã£o em LLMs atravÃ©s do fine-tuning com LoRA, medindo:

- **Ganho de especializaÃ§Ã£o**: Melhoria na tarefa Text-to-SQL usando o dataset Spider  
- **Perda de generalizaÃ§Ã£o**: RegressÃ£o de capacidade no benchmark MMLU (esquecimento catastrÃ³fico)

## ğŸ—ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ custom_metrics/
â”‚   â””â”€â”€ execution_accuracy.py         # MÃ©trica ExecutionAccuracy
â”œâ”€â”€ others/
â”‚   â””â”€â”€ Results/
â”‚       â”œâ”€â”€ avaliacao_Baseline_Model.csv
â”‚       â”œâ”€â”€ avaliacao_Fine-Tuned_Run_1.csv
â”‚       â”œâ”€â”€ avaliacao_Fine-Tuned_Run_2.csv
â”‚       â”œâ”€â”€ avaliacao_mmlu_resultados.csv
â”‚       â”œâ”€â”€ summary_fase3_accuracy.csv
â”‚    â”œâ”€â”€ mistral-7b-spider-run1.rar
â”‚    â”œâ”€â”€ mistral-7b-spider-run2.rar
|    â””â”€â”€ RelatÃ³rio tÃ©cnico-TP4.pdf
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ T4.ipynb                      # Notebook principal
â”œâ”€â”€ requirements.txt                 # DependÃªncias
â””â”€â”€ README.md                        # DocumentaÃ§Ã£o
```

## âš™ï¸ Ambiente de ExecuÃ§Ã£o

Este projeto foi desenvolvido para ser executado no ambiente Google Colab.  
Devido Ã s limitaÃ§Ãµes de armazenamento e memÃ³ria da versÃ£o gratuita do Colab, o Google Drive Ã© utilizado como soluÃ§Ã£o de armazenamento persistente.  
Antes de executar o notebook, certifique-se de ter no mÃ­nimo 3 GB de espaÃ§o livre no seu Drive.

## ğŸ“¦ Requisitos

VersÃµes das principais dependÃªncias:

- PyTorch: 2.6.0+cu124  
- Transformers: 4.52.4  
- PEFT: 0.15.2  
- TRL: 0.19.0  
- BitsAndBytes: 0.46.0  
- Datasets: 3.6.0  
- Accelerate: 1.8.1  
- DeepEval: 3.1.8  
- Pandas: 2.2.2  
- NumPy: 2.0.2  
- KaggleHub: 0.3.12

InstalaÃ§Ã£o:

```bash
pip install -r requirements.txt
```

## ğŸš€ Como Executar

### 1. Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd <nome-do-projeto>
```

### 2. Executar o Notebook

Abra o arquivo `scripts/T4.ipynb` no Google Colab.

### 3. Executar as CÃ©lulas

- CÃ©lula 1: Instala as dependÃªncias
- CÃ©lula 2: Conecta ao Google Drive e configura a API do Kaggle
- CÃ©lula 3: Fine-tuning dos modelos 
- CÃ©lulas seguintes: AvaliaÃ§Ã£o com ExecutionAccuracy e MMLU
- CÃ©lula final: Consolida os resultados em tabelas `.csv`

Os dados serÃ£o armazenados automaticamente no Google Drive, e reutilizados nas prÃ³ximas execuÃ§Ãµes.

## ğŸ“Š Resultados

Os resultados ficam salvos na pasta `others/Results/`:

- `avaliacao_Baseline_Model.csv`
- `avaliacao_Fine-Tuned_Run_1.csv`
- `avaliacao_Fine-Tuned_Run_2.csv`
- `avaliacao_mmlu_resultados.csv`
- `summary_fase3_accuracy.csv`
- `mistral-7b-spider-run1.rar`
- `mistral-7b-spider-run2.rar`

Esses arquivos contÃªm os resultados das fases 3 e 4 e os modelos treinados, que podem ser utilizados diretamente para inferÃªncia.

## ğŸ§ª MÃ©trica ExecutionAccuracy

Local: `custom_metrics/execution_accuracy.py`

Essa mÃ©trica avalia a acurÃ¡cia funcional de consultas SQL:

- Executa a query esperada e a query gerada nos bancos SQLite
- Compara os resultados (sem considerar a ordem)
- Retorna `1.0` se iguais, `0.0` se diferentes

## âœ… Checklist de ExecuÃ§Ã£o

- [x] Conta Google com Colab + GPU T4
- [x] API do Kaggle configurada
- [x] Dataset Spider baixado
- [x] Fine-tuning executado ou restaurado
- [x] AvaliaÃ§Ã£o ExecutionAccuracy
- [x] AvaliaÃ§Ã£o MMLU
- [x] Resultados exportados (.csv)
- [x] RelatÃ³rio TÃ©cnico (.pdf)

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido exclusivamente para fins acadÃªmicos na disciplina ICC220/PPGINF528 da Universidade Federal do Amazonas (UFAM).

**Autor(es)**: JACÃ“ MIRANDA  
**InstituiÃ§Ã£o**: Instituto de ComputaÃ§Ã£o - UFAM  
**Disciplina**: ICC220 - TÃ³picos Especiais em Bancos de Dados  
**Ano**: 2025
